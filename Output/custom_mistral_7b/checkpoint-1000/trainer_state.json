{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6787714237230612,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "learning_rate": 0.0002,
      "loss": 1.2256,
      "step": 25
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0002,
      "loss": 1.1957,
      "step": 50
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0002,
      "loss": 1.1795,
      "step": 75
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0002,
      "loss": 1.1804,
      "step": 100
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0002,
      "loss": 1.1218,
      "step": 125
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002,
      "loss": 1.1417,
      "step": 150
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002,
      "loss": 1.1397,
      "step": 175
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0002,
      "loss": 1.1525,
      "step": 200
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0002,
      "loss": 1.1452,
      "step": 225
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0002,
      "loss": 1.1283,
      "step": 250
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0002,
      "loss": 1.1311,
      "step": 275
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0002,
      "loss": 1.127,
      "step": 300
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0002,
      "loss": 1.1448,
      "step": 325
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0002,
      "loss": 1.1532,
      "step": 350
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0002,
      "loss": 1.1027,
      "step": 375
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0002,
      "loss": 1.1737,
      "step": 400
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0002,
      "loss": 1.1272,
      "step": 425
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0002,
      "loss": 1.1115,
      "step": 450
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0002,
      "loss": 1.1212,
      "step": 475
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0002,
      "loss": 1.1515,
      "step": 500
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0002,
      "loss": 1.142,
      "step": 525
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0002,
      "loss": 1.1248,
      "step": 550
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0002,
      "loss": 1.1332,
      "step": 575
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0002,
      "loss": 1.1193,
      "step": 600
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0002,
      "loss": 1.1246,
      "step": 625
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0002,
      "loss": 1.1248,
      "step": 650
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0002,
      "loss": 1.1179,
      "step": 675
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0002,
      "loss": 1.0891,
      "step": 700
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0002,
      "loss": 1.0924,
      "step": 725
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0002,
      "loss": 1.1175,
      "step": 750
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0002,
      "loss": 1.1074,
      "step": 775
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0002,
      "loss": 1.1338,
      "step": 800
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0002,
      "loss": 1.0971,
      "step": 825
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0002,
      "loss": 1.1117,
      "step": 850
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0002,
      "loss": 1.1123,
      "step": 875
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0002,
      "loss": 1.0747,
      "step": 900
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0002,
      "loss": 1.1302,
      "step": 925
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0002,
      "loss": 1.0977,
      "step": 950
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0002,
      "loss": 1.0936,
      "step": 975
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0002,
      "loss": 1.0894,
      "step": 1000
    }
  ],
  "logging_steps": 25,
  "max_steps": 1473,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 1.147125137719296e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
